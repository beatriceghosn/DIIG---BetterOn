{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"b-ENJa5oWoeS"},"outputs":[],"source":["!pip3 install SpeechRecognition\n","!pip install moviepy\n","!apt install imagemagick\n","!apt install libmagick++-dev\n","!cat /etc/ImageMagick-6/policy.xml | sed 's/none/read,write/g'> /etc/ImageMagick-6/policy.xml\n","!pip install ffmpeg-python"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1c6G2-CIWpX3"},"outputs":[],"source":["from moviepy.editor import *\n","import moviepy.editor as mp\n","import speech_recognition as sr\n","import ffmpeg\n","\n","# Function to transcribe audio from an audio file\n","def transcribe_audio(audio_path):\n","    recognizer = sr.Recognizer()\n","    audio_file = sr.AudioFile(audio_path)\n","\n","    with audio_file as source:\n","        audio = recognizer.record(source)  # Record the audio from the file\n","\n","    try:\n","        transcript = recognizer.recognize_google(audio)  # Perform transcription\n","        return transcript\n","    except sr.UnknownValueError:\n","        return \"Error: Could not transcribe audio\"\n","    except sr.RequestError as e:\n","        return f\"Error: {e}\"\n","\n","# Input video file path\n","unformatted_video_path = \"andre_test.webm\"\n","video_path = \"andre_test.mp4\"\n","\n","#Convert file format to mp4\n","ffmpeg.input(unformatted_video_path).output(video_path).run()\n","\n","# Load the video\n","video_clip = mp.VideoFileClip(video_path)\n","\n","# Initialize variables\n","segment_duration = 5  # Maximum duration of each audio segment (in seconds)\n","current_time = 0\n","text_clips = []\n","\n","# Process the video in segments\n","while current_time < video_clip.duration:\n","    # Calculate the duration of the current segment\n","    remaining_duration = min(segment_duration, video_clip.duration - current_time)\n","\n","    # Extract the audio segment from the video\n","    audio_segment = video_clip.subclip(current_time, current_time + remaining_duration)\n","    audio_path = f\"temp_audio_{current_time:.2f}.wav\"\n","    audio_segment.audio.write_audiofile(audio_path, codec='pcm_s16le')\n","\n","    # Transcribe the audio segment\n","    transcript = transcribe_audio(audio_path)\n","\n","    # Create a TextClip for the transcribed text\n","    text_clip = mp.TextClip(transcript, fontsize=15, color='white', bg_color='black')\n","    text_clip = text_clip.set_duration(remaining_duration)\n","    text_clips.append(text_clip)\n","\n","\n","    # Update the current time for the next segment\n","    current_time += remaining_duration\n","\n","# Concatenate the text clips to create synchronized text\n","text_clip = mp.concatenate_videoclips(text_clips, method=\"compose\")\n","text_clip = text_clip.set_position(('center', 'bottom')).set_duration(video_clip.duration)\n","\n","# Overlay the transcribed text on the video\n","video_with_text = mp.CompositeVideoClip([video_clip, text_clip])\n","\n","# Output video file path\n","output_video_path = \"output_video_with_text.mp4\"\n","\n","# Write the modified video to a file\n","video_with_text.write_videofile(output_video_path, codec='libx264', audio_codec='aac')\n","\n","print(f\"Video with synchronized transcribed text saved to {output_video_path}\")\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"12LcO0Y5lD8djNSdc6CaP0N0PF4CLRWts","timestamp":1710807042760}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}